text_model:
  class: uwul.model.AutoModelForCausalLMFactory
  factory: from_config
  args:
  - ./config/arch/NanoLLaMA-200m.json
  kwargs:
    torch_dtype: float16
    attn_implementation: flash_attention_2
tokenizer:
  class: transformers.LlamaTokenizer
  factory: from_pretrained
  args:
  - TinyLlama/TinyLlama-1.1B-Chat-v1.0
