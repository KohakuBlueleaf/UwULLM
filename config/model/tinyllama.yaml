text_model:
  class: transformers.LlamaForCausalLM
  factory: from_pretrained
  args:
  - TinyLlama/TinyLlama-1.1B-Chat-v1.0
  kwargs:
    torch_dtype: float16
    attn_implementation: flash_attention_2
tokenizer:
  class: transformers.LlamaTokenizer
  factory: from_pretrained
  args:
  - TinyLlama/TinyLlama-1.1B-Chat-v1.0
