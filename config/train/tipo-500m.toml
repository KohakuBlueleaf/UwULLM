seed=3407

[lightning]
    epochs=10
    batch_size=64
    dataloader_workers=8
    grad_acc={0=8, 5=16, 8=32} # epoch: grad_acc
    devices=[0, 1, 2, 3]
    precision="16-mixed"
    grad_clip=0.1
    grad_ckpt=true

    [lightning.logger]
        name="TITPOP-500M_dan-cc-coyo"
        project="NanoLLaMA"
        version="" # Empty for random id
        offline=false


[trainer]
    name="TITPOP-500M_dan-cc-coyo"
    lr=2e-4
    optimizer="torch.optim.AdamW"
    opt_configs = {"weight_decay"= 0.01, "betas"= [0.9, 0.98]}
    lr_scheduler = "torch.optim.lr_scheduler.CosineAnnealingLR"
    lr_sch_configs = {"T_max"= -1, "eta_min"= 5e-6} # -1 for auto
    use_warm_up=true
    warm_up_period = 100


[dataset]
    factory = {class = "dataset_private.titpop.TITPOPDatasetFactory"}
    split = ["danbooru", "gbc", "coyo"]
    [dataset.processor_config]
        cutoff_len = 2048


[model]
    config="./config/model/tipo-500m.yaml"